<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>Goal-Space Planning with Subgoal Models | Kevin Roice</title>
<meta name="keywords" content="Model-Based Reinforcement Learning, Temporal Abstraction, Planning">
<meta name="description" content="We propose a long-horizon background-planning algorithm for online RL. This used subgoal models (abstract in state &amp; time) for faster long-term decision making &amp; smarter value propagation.">
<meta name="author" content="Chunlok Lo*,&thinsp;Kevin Roice*,&thinsp;Parham Mohammad Panahi*,&thinsp;Scott M. Jordan,&thinsp;Adam White,&thinsp;Gabor Michuz,&thinsp;Farzane Aminmansour,&thinsp;Martha White">
<link rel="canonical" href="http://localhost:1313/papers/paper1/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.62a08063c7f522c9426972d30ec2fe0747e41ca7fa59f1363ea7fad7fdfed557.css" integrity="sha256-YqCAY8f1IslCaXLTDsL&#43;B0fkHKf6WfE2Pqf61/3&#43;1Vc=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/papers/paper1/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript><meta property="og:title" content="Goal-Space Planning with Subgoal Models" />
<meta property="og:description" content="We propose a long-horizon background-planning algorithm for online RL. This used subgoal models (abstract in state &amp; time) for faster long-term decision making &amp; smarter value propagation." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/papers/paper1/" />
<meta property="og:image" content="http://localhost:1313/paper1.png" /><meta property="article:section" content="papers" />
<meta property="article:published_time" content="2024-10-22T00:00:00+00:00" />
<meta property="article:modified_time" content="2024-10-28T00:00:00+00:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="http://localhost:1313/paper1.png" />
<meta name="twitter:title" content="Goal-Space Planning with Subgoal Models"/>
<meta name="twitter:description" content="We propose a long-horizon background-planning algorithm for online RL. This used subgoal models (abstract in state &amp; time) for faster long-term decision making &amp; smarter value propagation."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Papers",
      "item": "http://localhost:1313/papers/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Goal-Space Planning with Subgoal Models",
      "item": "http://localhost:1313/papers/paper1/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Goal-Space Planning with Subgoal Models",
  "name": "Goal-Space Planning with Subgoal Models",
  "description": "We propose a long-horizon background-planning algorithm for online RL. This used subgoal models (abstract in state \u0026amp; time) for faster long-term decision making \u0026amp; smarter value propagation.",
  "keywords": [
    "Model-Based Reinforcement Learning", "Temporal Abstraction", "Planning"
  ],
  "articleBody": " Download Paper Abstract This paper investigates a new approach to model-based reinforcement learning using background planning: mixing (approximate) dynamic programming updates and model-free updates, similar to the Dyna architecture. Background planning with learned models is often worse than model-free alternatives, such as Double DQN, even though the former uses significantly more memory and computation. The fundamental problem is that learned models can be inaccurate and often generate invalid states, especially when iterated many steps. In this paper, we avoid this limitation by constraining background planning to a given set of (abstract) subgoals and learning only local, subgoal-conditioned models. This goal-space planning (GSP) approach is more computationally efficient, naturally incorporates temporal abstraction for faster long-horizon planning, and avoids learning the transition dynamics entirely. We show that our GSP algorithm can propagate value from an abstract space in a manner that helps a variety of base learners learn significantly faster in different domains.\nFigure 6: Value Function update without (left) and with (right) Goal-Space Planning Citation Chunlok Lo, Kevin Roice, Parham Mohammad Panahi, Scott M. Jordan, Adam White, Gabor Michuz, Farzane Aminmansour, Martha White, “Goal-Space Planning with Subgoal Models”, Journal of Machine Learning Research 25 (-): 1-57.\n@article{gsp2024, author = {Chunlok Lo, Kevin Roice, Parham Mohammad Panahi, Scott M. Jordan, Adam White, Gabor Michuz, Farzane Aminmansour and Martha White}, year = {2024}, title ={Goal-Space Planning with Subgoal Models}, journal = {Journal of Machine Learning Research}, volume = {25}, number = {330}, pages = {1-57}} ",
  "wordCount" : "242",
  "inLanguage": "en",
  "image":"http://localhost:1313/paper1.png","datePublished": "2024-10-22T00:00:00Z",
  "dateModified": "2024-10-28T00:00:00Z",
  "author":[{
    "@type": "Person",
    "name": "Chunlok Lo*"
  }, {
    "@type": "Person",
    "name": "Kevin Roice*"
  }, {
    "@type": "Person",
    "name": "Parham Mohammad Panahi*"
  }, {
    "@type": "Person",
    "name": "Scott M. Jordan"
  }, {
    "@type": "Person",
    "name": "Adam White"
  }, {
    "@type": "Person",
    "name": "Gabor Michuz"
  }, {
    "@type": "Person",
    "name": "Farzane Aminmansour"
  }, {
    "@type": "Person",
    "name": "Martha White"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/papers/paper1/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Kevin Roice",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/favicon.ico"
    }
  }
}
</script>



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" integrity="sha384-wcIxkf4k558AjM3Yz3BBFQUbk/zgIYC2R0QpeeYb+TwlBVMrlgLqwRjRtGZiK7ww" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js" integrity="sha384-hIoBPJpTUs74ddyc4bFZSM1TVlQDA60VBbJS0oA934VSz82sBx1X7kSx2ATBDIyd" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous"
  onload="renderMathInElement(document.body);"></script>

<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          delimiters: [
            {left: '$$', right: '$$', display: true},
            {left: '$', right: '$', display: false},
            {left: "\\begin{equation}", right: "\\end{equation}", display: true},
            {left: "\\begin{equation*}", right: "\\end{equation*}", display: true},
            {left: "\\begin{align}", right: "\\end{align}", display: true},
            {left: "\\begin{align*}", right: "\\end{align*}", display: true},
            {left: "\\begin{alignat}", right: "\\end{alignat}", display: true},
            {left: "\\begin{gather}", right: "\\end{gather}", display: true},
            {left: "\\begin{CD}", right: "\\end{CD}", display: true},
          ],
          throwOnError : false
        });
    });
</script>
 


</head>

<body class="" id="top">

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Kevin Roice">
                <img src="http://localhost:1313/favicon2.ico" alt="" aria-label="logo"
                    height="18"
                    width="18">Kevin Roice</a>
            <div class="logo-switches">
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/papers/" title="Publications">
                    <span>Publications</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/courses/" title="Courses">
                    <span>Courses</span>
                </a>
            </li>
        </ul>
    </nav>
</header>

    <main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Goal-Space Planning with Subgoal Models
    </h1>
    <div class="post-meta"><span title='2024-10-22 00:00:00 +0000 UTC'>October 2024</span>&nbsp;&middot;&nbsp;Chunlok Lo*,&thinsp;Kevin Roice*,&thinsp;Parham Mohammad Panahi*,&thinsp;Scott M. Jordan,&thinsp;Adam White,&thinsp;Gabor Michuz,&thinsp;Farzane Aminmansour,&thinsp;Martha White&nbsp;&middot;&nbsp;<a href="http://jmlr.org/papers/v25/24-0040.html" rel="noopener noreferrer" target="_blank">JMLR 2024</a>

</div>
  </header> 
  <div class="post-content"><hr>
<h5 id="download">Download</h5>
<ul>
<li><a href="paper1.pdf">Paper</a>
</li>
</ul>
<!-- + [Code and data](https://github.com/pmichaillat/feru) -->
<hr>
<h5 id="abstract">Abstract</h5>
<p>This paper investigates a new approach to model-based reinforcement learning using background planning: mixing (approximate) dynamic programming updates and model-free updates, similar to the Dyna architecture. Background planning with learned models is often worse than model-free alternatives, such as Double DQN, even though the former uses significantly more memory and computation. The fundamental problem is that learned models can be inaccurate and often generate invalid states, especially when iterated many steps. In this paper, we avoid this limitation by constraining background planning to a given set of (abstract) subgoals and learning only local, subgoal-conditioned models. This goal-space planning (GSP) approach is more computationally efficient, naturally incorporates temporal abstraction for faster long-horizon planning, and avoids learning the transition dynamics entirely. We show that our GSP algorithm can propagate value from an abstract space in a manner that helps a variety of base learners learn significantly faster in different domains.</p>
<hr>
<h5 id="figure-6-value-function-update-without-left-and-with-right-goal-space-planning">Figure 6: Value Function update without (left) and with (right) Goal-Space Planning</h5>
<p><img loading="lazy" src="paper1.png" alt=""  />
</p>
<hr>
<h5 id="citation">Citation</h5>
<p>Chunlok Lo, Kevin Roice, Parham Mohammad Panahi, Scott M. Jordan, Adam White, Gabor Michuz, Farzane Aminmansour, Martha White, &ldquo;Goal-Space Planning with Subgoal Models&rdquo;, <em>Journal of Machine Learning Research</em> 25 (-): 1-57.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-BibTeX" data-lang="BibTeX"><span style="display:flex;"><span><span style="color:#0a0;text-decoration:underline">@article</span>{gsp2024,
</span></span><span style="display:flex;"><span><span style="color:#1e90ff">author</span> = <span style="color:#a50">{Chunlok Lo, Kevin Roice, Parham Mohammad Panahi, Scott M. Jordan, Adam White, Gabor Michuz, Farzane Aminmansour and Martha White}</span>,
</span></span><span style="display:flex;"><span><span style="color:#1e90ff">year</span> = <span style="color:#a50">{2024}</span>,
</span></span><span style="display:flex;"><span><span style="color:#1e90ff">title</span> =<span style="color:#a50">{Goal-Space Planning with Subgoal Models}</span>,
</span></span><span style="display:flex;"><span><span style="color:#1e90ff">journal</span> = <span style="color:#a50">{Journal of Machine Learning Research}</span>,
</span></span><span style="display:flex;"><span><span style="color:#1e90ff">volume</span> = <span style="color:#a50">{25}</span>,
</span></span><span style="display:flex;"><span><span style="color:#1e90ff">number</span> = <span style="color:#a50">{330}</span>,
</span></span><span style="display:flex;"><span><span style="color:#1e90ff">pages</span> = <span style="color:#a50">{1-57}</span>}
</span></span></code></pre></div><hr>
<!-- ##### Related material

+ [Presentation slides](presentation1.pdf)
+ [Summary of the paper](https://www.penguinrandomhouse.com/books/110403/unusual-uses-for-olive-oil-by-alexander-mccall-smith/) -->

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:1313/tags/model-based-reinforcement-learning/">Model-Based Reinforcement Learning</a></li>
      <li><a href="http://localhost:1313/tags/temporal-abstraction/">Temporal Abstraction</a></li>
      <li><a href="http://localhost:1313/tags/planning/">Planning</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="http://localhost:1313/">Kevin Roice</a></span> ·     
    <span>
    Powered by 
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/pmichaillat/hugo-website/" rel="noopener" target="_blank">a modified version</a>
         of 
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>
</html>
